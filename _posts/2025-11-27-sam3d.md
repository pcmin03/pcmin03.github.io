---
title: "[PaperReview] SAM 3D: 3Dfy Anything in Images"
categories: [3D Vision]
tags: [3D Vision, SAM3D, Image-to-3D, PaperReview]
article_header:
  type: overlay
  theme: dark
  background_color: '#0d1b2a'
  background_image:
    gradient: 'linear-gradient(135deg, rgba(13, 27, 42, .85), rgba(176, 125, 103, .65))'
    src: /assets/images/posts/sam3d/figure1.png
---

## Overview
메타가 공개한 SAM 3D는 자연 이미지 한 장과 SAM 계열 세그멘테이션 마스크만으로 **geometry · texture · layout**을 동시에 예측하는 3D foundation model이다.[^paper] 기존 single-view 기법이 synthetic 데이터나 단일 객체에 한정됐던 한계를, 대규모 human & model-in-the-loop 데이터 엔진과 다단계 학습 레시피로 넘어선다는 점이 핵심이다.

![Image](/assets/images/posts/sam3d/figure1.png){:.border.rounded}
<br/><sub>Figure 1. arXiv 원문에서 제시된 단일 이미지 → composable 3D scene 개요.[^paper]</sub>

## Pipeline & Architecture
- **입력**: RGB 이미지, SAM 3 기반 객체 마스크, (옵션) depth/point map.
- **Geometry Model**: image/point/shape/layout 토큰을 분리한 두-stream Transformer(Mixture of Transformers)로 64³ voxel과 pose/scale을 동시 예측.
- **Texture & Refinement Model**: rectified flow-matching Transformer가 geometry latent와 이미지 토큰을 조건으로 high-res mesh 또는 3D Gaussian splat을 생성.
- **Scene Composition**: 여러 객체의 layout을 월드 좌표에 정렬해 composable 3D scene을 구성.

![Image](/assets/images/posts/sam3d/figure2.png){:.border.rounded}
<br/><sub>Figure 2. Geometry → Texture & Refinement 두 단계 구조.[^paper]</sub>

## Data Engine & Training Recipe
1. **Synthetic Pretraining**: CAD 기반 대규모 shape·pose 분포로 토큰 표현을 초기화.
2. **Render-Paste Mid-training**: 자연 배경에 3D 객체를 합성하고 flying occluder/object swap 등을 적용해 clutter·occlusion 견고성을 확보.
3. **Real SFT + DPO Alignment**: 사람이 best-of-N으로 고른 후보와 3D 아티스트 제작 자산을 이용해 supervised fine-tuning을 수행하고, preference pair를 Direct Preference Optimization으로 학습해 사람이 선호하는 분포로 정렬.
4. **Iterative Data Engine**: 향상된 모델을 다시 annotation 파이프라인에 넣어 더 나은 후보를 생성하는 virtuous cycle을 구성.

## Results
- 새 벤치마크 **SA-3DAO**(in-the-wild 이미지 + 아티스트 mesh)에서 Chamfer·IoU·pose 지표 전반에 걸쳐 기존 image-to-3D 대비 의미 있는 이득을 보고한다.[^paper]
- Human study에서 **object-level 5:1, scene-level 6:1** 이상으로 SAM 3D 재구성이 선호되며, cluttered/occluded 장면에서 격차가 특히 크다.
- Geometry shortcut distillation으로 1-step/4-step 모드에서도 25-step 대비 38×/10× 빠른 추론을 유지하면서 품질 저하를 최소화한다.

## Takeaways for 3D Vision Workflows
- **Shape vs Layout 분리**: 토큰 레벨에서 geometry와 pose를 분리해 cross-attention으로만 교류시키는 구조는 style/content 혹은 domain-specific/invariant representation을 설계할 때도 유용한 패턴이다.
- **Render-Paste Augmentation**: foreground semantics를 유지한 채 배경·광원·occluder를 바꾸는 mid-training 전략은 2D cross-domain retrieval에도 그대로 응용 가능하다.
- **Preference-Aligned 3D**: LLM에서 쓰이던 DPO/RLHF 개념을 3D 자산 생성에 적용해 “사람이 실제로 더 선호하는” 결과를 보장한 점이 인상적이다.

[^paper]: SAM 3D Team et al., *SAM 3D: 3Dfy Anything in Images*, arXiv:2511.16624, 2025. Available at https://arxiv.org/pdf/2511.16624
